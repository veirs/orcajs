{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Orca Call Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbZ9pUom01BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflowjs\n",
        "!pip install pydub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP9z64bh0_eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print('\\u2022 Using TensorFlow Version:', tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtzlGGBw1Dwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from pydub import AudioSegment\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import os\n",
        "import glob\n",
        "import IPython\n",
        "from td_utils import *\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNeeIVXp1R1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPython.display.Audio(\"./raw_data/positives/1.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igipj2841gcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPython.display.Audio(\"./raw_data/negatives/4.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQgWMAH71jfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPython.display.Audio(\"./raw_data/backgrounds/1.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k22TwZK71sfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPython.display.Audio(\"audio_examples/example_train.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcdsUGIG1tf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = graph_spectrogram(\"audio_examples/example_train.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D299Es9n1xNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, data = wavfile.read(\"audio_examples/example_train.wav\")\n",
        "print(\"Time steps in audio recording before spectrogram\", data[:,0].shape)\n",
        "print(\"Time steps in input after spectrogram\", x.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV5SHPdk2NgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tx = 5511 # The number of time steps input to the model from the spectrogram\n",
        "n_freq = 101 # Number of frequencies input to the model at each time step of the spectrogram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I28XnUO2SWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ty = 1375 # The number of time steps in the output of our model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTTnKnl22XvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load audio segments using pydub \n",
        "positives, negatives, backgrounds = load_raw_audio()\n",
        "\n",
        "print(\"background len: \" + str(len(backgrounds[0])))    # Should be 10,000, since it is a 10 sec clip\n",
        "print(\"positive[0] len: \" + str(len(positives[0])))     # Maybe around 1000, since an orca call audio clip is usually around 1 sec (but varies a lot)\n",
        "print(\"positive[1] len: \" + str(len(positives[1])))     # Different orca call clips can have different lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMWtqRBw3cC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_time_segment(segment_ms):\n",
        "    \"\"\"\n",
        "    Gets a random time segment of duration segment_ms in a 10,000 ms audio clip.\n",
        "    \n",
        "    Arguments:\n",
        "    segment_ms -- the duration of the audio clip in ms (\"ms\" stands for \"milliseconds\")\n",
        "    \n",
        "    Returns:\n",
        "    segment_time -- a tuple of (segment_start, segment_end) in ms\n",
        "    \"\"\"\n",
        "    \n",
        "    segment_start = np.random.randint(low=0, high=10000-segment_ms)   # Make sure segment doesn't run past the 10sec background \n",
        "    segment_end = segment_start + segment_ms - 1\n",
        "    \n",
        "    return (segment_start, segment_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUyycHgY3jHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_overlapping(segment_time, previous_segments):\n",
        "    \"\"\"\n",
        "    Checks if the time of a segment overlaps with the times of existing segments.\n",
        "    \n",
        "    Arguments:\n",
        "    segment_time -- a tuple of (segment_start, segment_end) for the new segment\n",
        "    previous_segments -- a list of tuples of (segment_start, segment_end) for the existing segments\n",
        "    \n",
        "    Returns:\n",
        "    True if the time segment overlaps with any of the existing segments, False otherwise\n",
        "    \"\"\"\n",
        "    \n",
        "    segment_start, segment_end = segment_time\n",
        "    \n",
        "    overlap = False\n",
        "    \n",
        "    for previous_start, previous_end in previous_segments:\n",
        "        if segment_start <= previous_end and segment_end >= previous_start:\n",
        "            overlap = True\n",
        "\n",
        "    return overlap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT8jDm_C3oPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overlap1 = is_overlapping((950, 1430), [(2000, 2550), (260, 949)])\n",
        "overlap2 = is_overlapping((2305, 2950), [(824, 1532), (1900, 2305), (3424, 3656)])\n",
        "print(\"Overlap 1 = \", overlap1)\n",
        "print(\"Overlap 2 = \", overlap2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHxjqYif3yXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def insert_audio_clip(background, audio_clip, previous_segments):\n",
        "    \"\"\"\n",
        "    Insert a new audio segment over the background noise at a random time step, ensuring that the \n",
        "    audio segment does not overlap with existing segments.\n",
        "    \n",
        "    Arguments:\n",
        "    background -- a 10 second background audio recording.  \n",
        "    audio_clip -- the audio clip to be inserted/overlaid. \n",
        "    previous_segments -- times where audio segments have already been placed\n",
        "    \n",
        "    Returns:\n",
        "    new_background -- the updated background audio\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the duration of the audio clip in ms\n",
        "    segment_ms = len(audio_clip)\n",
        "    \n",
        "    # Step 1: Use one of the helper functions to pick a random time segment onto which to insert \n",
        "    # the new audio clip. (≈ 1 line)\n",
        "    segment_time = get_random_time_segment(segment_ms)\n",
        "    \n",
        "    # Step 2: Check if the new segment_time overlaps with one of the previous_segments. If so, keep \n",
        "    # picking new segment_time at random until it doesn't overlap. (≈ 2 lines)\n",
        "    while is_overlapping(segment_time, previous_segments):\n",
        "        segment_time = get_random_time_segment(segment_ms)\n",
        "\n",
        "    # Step 3: Add the new segment_time to the list of previous_segments (≈ 1 line)\n",
        "    previous_segments.append(segment_time)\n",
        "    \n",
        "    # Step 4: Superpose audio segment and background\n",
        "    new_background = background.overlay(audio_clip, position = segment_time[0])\n",
        "    \n",
        "    return new_background, segment_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLqfs-638vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(5)\n",
        "audio_clip, segment_time = insert_audio_clip(backgrounds[0], positives[0], [(3790, 4400)])\n",
        "audio_clip.export(\"insert_test.wav\", format=\"wav\")\n",
        "print(\"Segment Time: \", segment_time)\n",
        "IPython.display.Audio(\"insert_test.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-xaEA3y4Gii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Expected audio\n",
        "IPython.display.Audio(\"audio_examples/insert_reference.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw12eLA84MIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def insert_ones(y, segment_end_ms):\n",
        "    \"\"\"\n",
        "    Update the label vector y. The labels of the 50 output steps strictly after the end of the segment \n",
        "    should be set to 1. By strictly we mean that the label of segment_end_y should be 0 while, the\n",
        "    50 followinf labels should be ones.\n",
        "    \n",
        "    \n",
        "    Arguments:\n",
        "    y -- numpy array of shape (1, Ty), the labels of the training example\n",
        "    segment_end_ms -- the end time of the segment in ms\n",
        "    \n",
        "    Returns:\n",
        "    y -- updated labels\n",
        "    \"\"\"\n",
        "    \n",
        "    # duration of the background (in terms of spectrogram time-steps)\n",
        "    segment_end_y = int(segment_end_ms * Ty / 10000.0)\n",
        "    \n",
        "    # Add 1 to the correct index in the background label (y)\n",
        "    for i in range(segment_end_y + 1, segment_end_y + 51):\n",
        "        if i < Ty:\n",
        "            y[0, i] = 1\n",
        "    \n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adfu9VKs4ZYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr1 = insert_ones(np.zeros((1, Ty)), 9700)\n",
        "plt.plot(insert_ones(arr1, 4251)[0,:])\n",
        "print(\"sanity checks:\", arr1[0][1333], arr1[0][634], arr1[0][635])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzhj4P564cib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_training_example(background, positives, negatives):\n",
        "    \"\"\"\n",
        "    Creates a training example with a given background, positives, and negatives.\n",
        "    \n",
        "    Arguments:\n",
        "    background -- a 10 second background audio recording\n",
        "    positives -- a list of audio segments of orca calls\n",
        "    negatives -- a list of audio segments of random sounds that are not orca calls\n",
        "    \n",
        "    Returns:\n",
        "    x -- the spectrogram of the training example\n",
        "    y -- the label at each time step of the spectrogram\n",
        "    \"\"\"\n",
        "    \n",
        "    # Set the random seed\n",
        "    np.random.seed(18)\n",
        "    \n",
        "    # Make background quieter\n",
        "    background = background - 20\n",
        "\n",
        "    # Step 1: Initialize y (label vector) of zeros (≈ 1 line)\n",
        "    y = np.zeros((1, Ty))\n",
        "\n",
        "    # Step 2: Initialize segment times as empty list (≈ 1 line)\n",
        "    previous_segments = []\n",
        "    \n",
        "    # Select 0-4 random positive audio clips from the entire list of \"positives\" recordings\n",
        "    number_of_positives = np.random.randint(0, 5)\n",
        "    random_indices = np.random.randint(len(positives), size=number_of_positives)\n",
        "    random_positives = [positives[i] for i in random_indices]\n",
        "    \n",
        "    # Step 3: Loop over randomly selected positive clips and insert in background\n",
        "    for random_positive in random_positives:\n",
        "        # Insert the audio clip on the background\n",
        "        background, segment_time = insert_audio_clip(background, random_positive, previous_segments)\n",
        "        # Retrieve segment_start and segment_end from segment_time\n",
        "        segment_start, segment_end = segment_time\n",
        "        # Insert labels in \"y\"\n",
        "        y = insert_ones(y, segment_end_ms=segment_end)\n",
        "\n",
        "    # Select 0-2 random negative audio recordings from the entire list of \"negatives\" recordings\n",
        "    number_of_negatives = np.random.randint(0, 3)\n",
        "    random_indices = np.random.randint(len(negatives), size=number_of_negatives)\n",
        "    random_negatives = [negatives[i] for i in random_indices]\n",
        "\n",
        "    # Step 4: Loop over randomly selected negative clips and insert in background\n",
        "    for random_negative in random_negatives:\n",
        "        # Insert the audio clip on the background \n",
        "        background, _ = insert_audio_clip(background, random_negative, previous_segments)\n",
        "    \n",
        "    # Standardize the volume of the audio clip \n",
        "    background = match_target_amplitude(background, -20.0)\n",
        "\n",
        "    # Export new training example \n",
        "    file_handle = background.export(\"train\" + \".wav\", format=\"wav\")\n",
        "    print(\"File (train.wav) was saved in your directory.\")\n",
        "    \n",
        "    # Get and plot spectrogram of the new recording (background with superposition of positive and negatives)\n",
        "    x = graph_spectrogram(\"train.wav\")\n",
        "    \n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krOYPORl655E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = create_training_example(backgrounds[0], positives, negatives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvAfcwsx7HVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPython.display.Audio(\"train.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy8G8At67H-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPython.display.Audio(\"audio_examples/train_reference.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1k6CBad7LtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rfAP-q77N4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load preprocessed training examples\n",
        "X = np.load(\"./XY_train/X.npy\")\n",
        "Y = np.load(\"./XY_train/Y.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF54ASJL7RGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load preprocessed dev set examples\n",
        "X_dev = np.load(\"./XY_dev/X_dev.npy\")\n",
        "Y_dev = np.load(\"./XY_dev/Y_dev.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXEZbaEo7UND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
        "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI8x9kKA7jBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(input_shape):\n",
        "    \"\"\"\n",
        "    Function creating the model's graph in Keras.\n",
        "    \n",
        "    Argument:\n",
        "    input_shape -- shape of the model's input data (using Keras conventions)\n",
        "\n",
        "    Returns:\n",
        "    model -- Keras model instance\n",
        "    \"\"\"\n",
        "    \n",
        "    X_input = Input(shape = input_shape)\n",
        "    \n",
        "    # Step 1: CONV layer\n",
        "    X = Conv1D(196, kernel_size=15, strides=4)(X_input)                                 # CONV1D\n",
        "    X = BatchNormalization()(X)                                 # Batch normalization\n",
        "    X = Activation('relu')(X)                                 # ReLu activation\n",
        "    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
        "\n",
        "    # Step 2: First GRU Layer\n",
        "    X = GRU(units = 128, return_sequences = True)(X) # GRU (use 128 units and return the sequences)\n",
        "    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
        "    X = BatchNormalization()(X)                                 # Batch normalization\n",
        "    \n",
        "    # Step 3: Second GRU Layer\n",
        "    X = GRU(units = 128, return_sequences = True)(X)   # GRU (use 128 units and return the sequences)\n",
        "    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
        "    X = BatchNormalization()(X)                                  # Batch normalization\n",
        "    X = Dropout(0.8)(X)                                  # dropout (use 0.8)\n",
        "    \n",
        "    # Step 4: Time-distributed dense layer\n",
        "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
        "\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FtdTN9a7tMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model(input_shape = (Tx, n_freq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGZRR9V67wTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOGiDfd07yaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('./models/tr_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sftdCyZQ8EOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtXGr0QC8IFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, Y, batch_size = 5, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHlCLXeQ8e1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc = model.evaluate(X_dev, Y_dev)\n",
        "print(\"Dev set accuracy = \", acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT9fgUKD8pdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_orcacall(filename):\n",
        "    plt.subplot(2, 1, 1)\n",
        "\n",
        "    x = graph_spectrogram(filename)\n",
        "    # the spectogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model\n",
        "    x  = x.swapaxes(0,1)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    predictions = model.predict(x)\n",
        "    \n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(predictions[0,:,0])\n",
        "    plt.ylabel('probability')\n",
        "    plt.show()\n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEj_12CZ8zdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chime_file = \"audio_examples/chime.wav\"\n",
        "def chime_on_positive(filename, predictions, threshold):\n",
        "    audio_clip = AudioSegment.from_wav(filename)\n",
        "    chime = AudioSegment.from_wav(chime_file)\n",
        "    Ty = predictions.shape[1]\n",
        "    # Step 1: Initialize the number of consecutive output steps to 0\n",
        "    consecutive_timesteps = 0\n",
        "    # Step 2: Loop over the output steps in the y\n",
        "    for i in range(Ty):\n",
        "        # Step 3: Increment consecutive output steps\n",
        "        consecutive_timesteps += 1\n",
        "        # Step 4: If prediction is higher than the threshold and more than 75 consecutive output steps have passed\n",
        "        if predictions[0,i,0] > threshold and consecutive_timesteps > 75:\n",
        "            # Step 5: Superpose audio and background using pydub\n",
        "            audio_clip = audio_clip.overlay(chime, position = ((i / Ty) * audio_clip.duration_seconds)*1000)\n",
        "            # Step 6: Reset consecutive output steps to 0\n",
        "            consecutive_timesteps = 0\n",
        "        \n",
        "    audio_clip.export(\"chime_output.wav\", format='wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F53FBlO586wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IPython.display.Audio(\"./raw_data/dev/2.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtXkb9jX887S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename  = \"./raw_data/dev/2.wav\"\n",
        "prediction = detect_orcacall(filename)\n",
        "chime_on_positive(filename, prediction, 0.5)\n",
        "IPython.display.Audio(\"./chime_output.wav\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP0G1eUn9Hr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "saved_model_path = \"./{}.h5\".format(int(time.time()))\n",
        "\n",
        "tf.keras.experimental.export_saved_model(model, saved_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHGCauWX9epD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter --input_format=keras {saved_model_path} ./"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
